{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# I- Begin like ViT_TransferLearning.py",
   "id": "b9e76c46a8afe45f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:55:08.154883Z",
     "start_time": "2024-06-18T19:55:08.121189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py as h5\n",
    "import shutil\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from random import random\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from transformers import ViTModel\n",
    "import torch.optim as optim\n",
    "from Utilities import *\n",
    "\n",
    "# Paths\n",
    "data_path = '/home/rbertille/data/pycharm/ViT_project/pycharm_Geoflow/GeoFlow/Tutorial/Datasets/'\n",
    "dataset_name = 'TutorialDataset'\n",
    "files_path = os.path.join(data_path, dataset_name)\n",
    "\n",
    "train_folder = glob.glob(f'{files_path}/train/*')\n",
    "validate_folder = glob.glob(f'{files_path}/validate/*')\n",
    "test_folder = glob.glob(f'{files_path}/test/*')\n",
    "\n",
    "#def data augmentation\n",
    "data_aug = transforms.Compose(\n",
    "    [\n",
    "        DeadTraces(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.data, self.labels = self.load_data_from_folder(folder)\n",
    "        self.transform = transform #ici\n",
    "\n",
    "    def load_data_from_folder(self, folder):\n",
    "        data = []\n",
    "        labels = []\n",
    "\n",
    "        for file_path in folder:\n",
    "            with h5.File(file_path, 'r') as h5file:\n",
    "                inputs = h5file['shotgather'][:]\n",
    "                #take second half only= Z component\n",
    "                inputs = inputs[:,int(inputs.shape[1]/2):]\n",
    "                labels_data = h5file['vsdepth'][:]\n",
    "\n",
    "                # print('data shape:',inputs.shape)\n",
    "                # print('min data=',np.min(inputs))\n",
    "                inputs = (inputs - np.min(inputs)) / (np.max(inputs) - np.min(inputs))\n",
    "\n",
    "                # reshape data\n",
    "                inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "                transform_resize = transforms.Compose([\n",
    "                    transforms.ToPILImage(),\n",
    "                    transforms.Resize((224, 224)),\n",
    "                    transforms.ToTensor()\n",
    "                ])\n",
    "                inputs = transform_resize(inputs)\n",
    "\n",
    "                if inputs.shape[0] == 1:  # Si l'image est en grayscale\n",
    "                    inputs = inputs.repeat(3, 1, 1)  # Convertir en RGB\n",
    "                inputs = inputs.numpy()\n",
    "\n",
    "                data.append(inputs)\n",
    "                labels.append(labels_data)\n",
    "\n",
    "        data = np.array(data)\n",
    "\n",
    "        labels = np.array(labels)\n",
    "        return data, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.data[idx]\n",
    "        labels = self.labels[idx]\n",
    "\n",
    "        # Convert inputs and labels to Tensors\n",
    "        inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        sample = {'data': inputs, 'label': labels}\n",
    "\n",
    "        if self.transform:\n",
    "            sample['data'] = self.transform(sample['data']) #ici\n",
    "\n",
    "        return sample\n",
    "\n",
    "def create_datasets(data_path, dataset_name):\n",
    "    train_folder = glob.glob(os.path.join(data_path, dataset_name, 'train', '*'))\n",
    "    validate_folder = glob.glob(os.path.join(data_path, dataset_name, 'validate', '*'))\n",
    "    test_folder = glob.glob(os.path.join(data_path, dataset_name, 'test', '*'))\n",
    "\n",
    "    train_dataset = CustomDataset(train_folder,transform=data_aug)\n",
    "    validate_dataset = CustomDataset(validate_folder)\n",
    "    test_dataset = CustomDataset(test_folder)\n",
    "\n",
    "    return train_dataset, validate_dataset, test_dataset\n",
    "\n",
    "\n",
    "train_dataset, validate_dataset, test_dataset = create_datasets(data_path, dataset_name)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=None)"
   ],
   "id": "d2ad31bd93d83c71",
   "execution_count": 36,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:55:08.789091Z",
     "start_time": "2024-06-18T19:55:08.182222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_a_sample(train_dataloader, i=0):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5 * 1))\n",
    "\n",
    "# Sélectionner le premier échantillon\n",
    "    sample = train_dataloader.dataset[i]\n",
    "    image = sample['data']\n",
    "    label= sample['label']\n",
    "    print('shape image=',image.shape)\n",
    "\n",
    "    # Afficher l'image dans la première colonne\n",
    "    axs[0].imshow(image[0], aspect='auto', cmap='gray')\n",
    "    axs[0].set_title(f'Original Shot Gather {i + 1} reshaped 224x224')\n",
    "    axs[0].set_xlabel('Distance (grid points, reshaped)')\n",
    "    axs[0].set_ylabel('Time (dt, reshaped)')\n",
    "\n",
    "    # Afficher le label dans la deuxième colonne\n",
    "    axs[1].plot(label, range(len(label)))\n",
    "    axs[1].invert_yaxis()\n",
    "    axs[1].set_xlabel('Vs (m/s)')\n",
    "    axs[1].set_ylabel('Depth (grid points)')\n",
    "    axs[1].set_title(f'Vs Depth ')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_a_sample(train_dataloader, i=0)"
   ],
   "id": "c6bfbaf91eaf4149",
   "execution_count": 37,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# II - Data Augmentation",
   "id": "89c9daeb30ba6005"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:55:08.796839Z",
     "start_time": "2024-06-18T19:55:08.791090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add dead traces\n",
    "def add_dead_traces(image, dead_trace_ratio=0.04):\n",
    "    ''''\n",
    "    Replace some random traces by dead traces to the data: a dead trace is a trace (=column) with all values set to 1\n",
    "    \n",
    "    :param image: 3D tensor of shape (C, H, W) where C is the number of channels, H is the height and W is the width\n",
    "    :param dead_trace_ratio: From 0 to 1, the ratio of dead traces to add\n",
    "    \n",
    "    :return: augmented_data: 3D tensor of shape (C, H, W) with some dead traces\n",
    "    '''\n",
    "    # Make a copy of the original image\n",
    "    augmented_data = image.clone() if isinstance(image, torch.Tensor) else image.copy()\n",
    "    \n",
    "    #count colums in the data\n",
    "    num_columns = augmented_data[0].shape[1]\n",
    "    #print('nb traces=',num_columns)\n",
    "    #choose missing_trace_ratio % of the traces to be dead traces randomly\n",
    "    num_dead_traces = int(num_columns * dead_trace_ratio)\n",
    "    #print('nb dead traces',num_dead_traces)\n",
    "    #choose the indices of the dead traces\n",
    "    dead_traces_indices = random.sample(range(num_columns), num_dead_traces)\n",
    "    #print('indices of the dead traces:',dead_traces_indices)\n",
    "    \n",
    "    #set the values of the dead traces to 1\n",
    "    augmented_data[:,:, dead_traces_indices] = 1\n",
    "    return augmented_data"
   ],
   "id": "c0a63c30ab58a3b5",
   "execution_count": 38,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:55:08.826971Z",
     "start_time": "2024-06-18T19:55:08.798501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#same aumgentation but, but we want to create a custom transform to apply it on the data without take to much memory\n",
    "\n",
    "class DeadTraces:\n",
    "    \"\"\"\n",
    "    Applies dead traces to a shotgather.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dead_trace_ratio=0.04):\n",
    "        self.dead_trace_ratio = dead_trace_ratio\n",
    "    def add_dead_traces(self,image, dead_trace_ratio):\n",
    "        ''''\n",
    "        Replace some random traces by dead traces to the data: a dead trace is a trace (=column) with all values set to 1\n",
    "\n",
    "        :param image: 3D tensor of shape (C, H, W) where C is the number of channels, H is the height and W is the width\n",
    "        :param dead_trace_ratio: From 0 to 1, the ratio of dead traces to add\n",
    "\n",
    "        :return: augmented_data: 3D tensor of shape (C, H, W) with some dead traces\n",
    "        '''\n",
    "        img2D=0\n",
    "        #verify if image is (h,w) or (c,h,w):\n",
    "        if len(image.shape)==2:\n",
    "            image = image.unsqueeze(0)\n",
    "            img2D=1\n",
    "\n",
    "\n",
    "\n",
    "        # Make a copy of the original image\n",
    "        augmented_data = image.clone() if isinstance(image, torch.Tensor) else image.copy()\n",
    "\n",
    "        # count colums in the data\n",
    "        num_columns = augmented_data[0].shape[1]\n",
    "        # print('nb traces=',num_columns)\n",
    "        # choose missing_trace_ratio % of the traces to be dead traces randomly\n",
    "        num_dead_traces = int(num_columns * dead_trace_ratio)\n",
    "        # print('nb dead traces',num_dead_traces)\n",
    "        # choose the indices of the dead traces\n",
    "        dead_traces_indices = random.sample(range(num_columns), num_dead_traces)\n",
    "        # print('indices of the dead traces:',dead_traces_indices)\n",
    "\n",
    "        # set the values of the dead traces to 1\n",
    "        augmented_data[:, :, dead_traces_indices] = 1\n",
    "        if img2D==1:\n",
    "            augmented_data=augmented_data.squeeze(0)\n",
    "        return augmented_data\n",
    "\n",
    "    def __call__(self, sample: torch.Tensor) -> torch.Tensor:\n",
    "        return self.add_dead_traces(sample, self.dead_trace_ratio)\n"
   ],
   "id": "a815c1b4ea21fc86",
   "execution_count": 39,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:55:09.177919Z",
     "start_time": "2024-06-18T19:55:08.829244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#apply the transform on the first example\n",
    "\n",
    "#create transform\n",
    "# Compose the custom augmentations with available augmentations.\n",
    "data_aug = transforms.Compose(\n",
    "    [\n",
    "        DeadTraces(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#apply on our example:\n",
    "image=train_dataloader.dataset.data[0]\n",
    "modified_image = data_aug(image)\n",
    "print('shape image:',train_dataloader.dataset.data[0].shape)\n",
    "#plot the modified example\n",
    "plt.imshow(modified_image[0], aspect='auto', cmap='gray')\n"
   ],
   "id": "27af02118b7d882f",
   "execution_count": 40,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:55:10.088863Z",
     "start_time": "2024-06-18T19:55:09.179571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add missing signal: replace some traces by average value\n",
    "def Missing_traces(image, missing_trace_ratio=0.04):\n",
    "    ''''\n",
    "    Replace some random traces by missing traces to the data: a missing trace is a trace (=column) with all values set to the average value of the trace\n",
    "    \n",
    "    :param image: 3D tensor of shape (C, H, W) where C is the number of channels, H is the height and W is the width\n",
    "    :param missing_trace_ratio: From 0 to 1, the ratio of missing traces to add\n",
    "    \n",
    "    :return: augmented_data: 3D tensor of shape (C, H, W) with some missing traces\n",
    "    '''\n",
    "    # Make a copy of the original image\n",
    "    augmented_data = image.clone() if isinstance(image, torch.Tensor) else image.copy()\n",
    "    \n",
    "    #count colums in the data\n",
    "    num_columns = augmented_data[0].shape[1]\n",
    "    #print('nb traces=',num_columns)\n",
    "    #choose missing_trace_ratio % of the traces to be dead traces randomly\n",
    "    num_missing_traces = int(num_columns * missing_trace_ratio)\n",
    "    #print('nb missing traces',num_dead_traces)\n",
    "    #choose the indices of the dead traces\n",
    "    missing_traces_indices = random.sample(range(num_columns), num_missing_traces)\n",
    "    #print('indices of the missing traces:',missing_traces_indices)\n",
    "    \n",
    "    average_value = augmented_data[:,:, missing_traces_indices].mean()\n",
    "    \n",
    "    #set the values of the dead traces to average\n",
    "    augmented_data[:,:, missing_traces_indices] = average_value\n",
    "    return augmented_data\n",
    "\n",
    "#Apply on first example\n",
    "#plot example 1, which is the first original example\n",
    "plot_a_sample(train_dataloader, i=0)\n",
    "# apply\n",
    "image = train_dataloader.dataset.data[0]\n",
    "image_dead = Missing_traces(image, missing_trace_ratio=0.04)\n",
    "#plot the modified example\n",
    "plt.imshow(image_dead[0], aspect='auto', cmap='gray')"
   ],
   "id": "40b35f5d4337097c",
   "execution_count": 41,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:55:10.403155Z",
     "start_time": "2024-06-18T19:55:10.090629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MissingTraces:\n",
    "    \"\"\"\n",
    "    Applies dead traces to a shotgather.\n",
    "    \"\"\"\n",
    "    def __init__(self, missing_trace_ratio=0.04):\n",
    "        self.missing_trace_ratio = missing_trace_ratio\n",
    "\n",
    "    def Missing_traces(self,image, missing_trace_ratio):\n",
    "        ''''\n",
    "        Replace some random traces by missing traces to the data: a missing trace is a trace (=column) with all values set to the average value of the trace\n",
    "\n",
    "        :param image: 3D tensor of shape (C, H, W) where C is the number of channels, H is the height and W is the width\n",
    "        :param missing_trace_ratio: From 0 to 1, the ratio of missing traces to add\n",
    "\n",
    "        :return: augmented_data: 3D tensor of shape (C, H, W) with some missing traces\n",
    "        '''\n",
    "\n",
    "        img2D = 0\n",
    "        # verify if image is (h,w) or (c,h,w):\n",
    "        if len(image.shape) == 2:\n",
    "            image = image.unsqueeze(0)\n",
    "            img2D = 1\n",
    "\n",
    "        # Make a copy of the original image\n",
    "        augmented_data = image.clone() if isinstance(image, torch.Tensor) else image.copy()\n",
    "\n",
    "        # count colums in the data\n",
    "        num_columns = augmented_data[0].shape[1]\n",
    "        # print('nb traces=',num_columns)\n",
    "        # choose missing_trace_ratio % of the traces to be dead traces randomly\n",
    "        num_missing_traces = int(num_columns * missing_trace_ratio)\n",
    "        # print('nb missing traces',num_dead_traces)\n",
    "        # choose the indices of the dead traces\n",
    "        missing_traces_indices = random.sample(range(num_columns), num_missing_traces)\n",
    "        # print('indices of the missing traces:',missing_traces_indices)\n",
    "\n",
    "        average_value = augmented_data[:, :, missing_traces_indices].mean()\n",
    "\n",
    "        # set the values of the dead traces to average\n",
    "        augmented_data[:, :, missing_traces_indices] = average_value\n",
    "        if img2D==1:\n",
    "            augmented_data=augmented_data.squeeze(0)\n",
    "\n",
    "        return augmented_data\n",
    "\n",
    "    def __call__(self, sample: torch.Tensor) -> torch.Tensor:\n",
    "        return self.Missing_traces(sample, self.missing_trace_ratio)\n",
    "    \n",
    "#create a transform using MissingTraces\n",
    "data_aug = transforms.Compose(\n",
    "    [\n",
    "        MissingTraces(),\n",
    "        DeadTraces()\n",
    "    ]\n",
    ")\n",
    "\n",
    "#apply on our example:\n",
    "image=train_dataloader.dataset.data[0]\n",
    "modified_image = data_aug(image)\n",
    "print('shape image:',train_dataloader.dataset.data[0].shape)\n",
    "#plot the modified example\n",
    "plt.imshow(modified_image[0], aspect='auto', cmap='gray')"
   ],
   "id": "92a8e7c6e9e94fcf",
   "execution_count": 42,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:55:10.420903Z",
     "start_time": "2024-06-18T19:55:10.404751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset, validate_dataset, test_dataset = create_datasets(data_path, dataset_name)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=None)"
   ],
   "id": "3477b5377afaf3f0",
   "execution_count": 43,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:55:11.446739Z",
     "start_time": "2024-06-18T19:55:10.422425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#plot an example\n",
    "plot_a_sample(train_dataloader, i=0)"
   ],
   "id": "9a40dd2578d07010",
   "execution_count": 44,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# II - For ViT_network.py\n",
   "id": "a25eb9a8906fdce3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:55:11.469090Z",
     "start_time": "2024-06-18T19:55:11.448693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.data, self.labels = self.load_data_from_folder(folder)\n",
    "        self.transform = transform\n",
    "\n",
    "    def load_data_from_folder(self, folder):\n",
    "        data = []\n",
    "        labels = []\n",
    "\n",
    "        for file_path in folder:\n",
    "            with h5.File(file_path, 'r') as h5file:\n",
    "                inputs = h5file['shotgather'][:]\n",
    "                len_inp = inputs.shape[1]\n",
    "                half_ind= len_inp//2\n",
    "                inputs = h5file['shotgather'][:,half_ind:]\n",
    "                labels_data = h5file['vsdepth'][:]\n",
    "\n",
    "                inputs = (inputs - np.min(inputs)) / (np.max(inputs) - np.min(inputs))\n",
    "                \n",
    "                transform_tensor = transforms.Compose([\n",
    "                    transforms.ToTensor()\n",
    "                ])\n",
    "                \n",
    "                \n",
    "                inputs = transform_tensor(inputs)\n",
    "\n",
    "                data.append(inputs)\n",
    "                labels.append(labels_data)\n",
    "\n",
    "        data = np.array(data)\n",
    "\n",
    "\n",
    "        labels = np.array(labels)\n",
    "        return data, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.data[idx]\n",
    "        labels = self.labels[idx]\n",
    "\n",
    "        # Convert inputs and labels to Tensors\n",
    "        inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            inputs = self.transform(inputs)\n",
    "            \n",
    "        sample = {'data': inputs, 'label': labels}\n",
    "\n",
    "        return sample\n",
    "\n",
    "def create_datasets(data_path, dataset_name):\n",
    "    train_folder = glob.glob(os.path.join(data_path, dataset_name, 'train', '*'))\n",
    "    validate_folder = glob.glob(os.path.join(data_path, dataset_name, 'validate', '*'))\n",
    "    test_folder = glob.glob(os.path.join(data_path, dataset_name, 'test', '*'))\n",
    "\n",
    "    train_dataset = CustomDataset(train_folder,transform=data_aug)\n",
    "    validate_dataset = CustomDataset(validate_folder)\n",
    "    test_dataset = CustomDataset(test_folder)\n",
    "\n",
    "    return train_dataset, validate_dataset, test_dataset\n",
    "\n",
    "\n",
    "train_dataset, validate_dataset, test_dataset= create_datasets(data_path, dataset_name)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)"
   ],
   "id": "192d07d95eb5f812",
   "execution_count": 45,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:55:12.101396Z",
     "start_time": "2024-06-18T19:55:11.472569Z"
    }
   },
   "cell_type": "code",
   "source": "plot_a_sample(train_dataloader, i=0)",
   "id": "97caa00d4b27bf55",
   "execution_count": 46,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:01:10.864749Z",
     "start_time": "2024-06-18T20:01:10.231826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#add gaussian noise\n",
    "\n",
    "class GaussianNoise:\n",
    "    \"\"\"\n",
    "    Adds Gaussian noise to a shotgather.\n",
    "    \"\"\"\n",
    "    def __init__(self, mean=0., std=0.01):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "\n",
    "    def add_gaussian_noise(self, image, mean, std):\n",
    "        '''\n",
    "        Add Gaussian noise to the data\n",
    "\n",
    "        :param image: 3D tensor of shape (C, H, W) where C is the number of channels, H is the height and W is the width\n",
    "        :param mean: mean of the Gaussian noise\n",
    "        :param std: standard deviation of the Gaussian noise\n",
    "\n",
    "        :return: augmented_data: 3D tensor of shape (C, H, W) with Gaussian noise\n",
    "        '''\n",
    "        # Make a copy of the original image\n",
    "        augmented_data = image.clone() if isinstance(image, torch.Tensor) else image.copy()\n",
    "\n",
    "        # Add Gaussian noise\n",
    "        noise = torch.randn(augmented_data.shape) * std + mean\n",
    "        augmented_data += noise\n",
    "\n",
    "        return augmented_data\n",
    "\n",
    "    def __call__(self, sample: torch.Tensor) -> torch.Tensor:\n",
    "        return self.add_gaussian_noise(sample, self.mean, self.std)\n",
    "\n",
    "# Exemple d'utilisation :\n",
    "data_aug = transforms.Compose(\n",
    "    [\n",
    "        GaussianNoise(mean=0., std=0.1),\n",
    "        MissingTraces(),\n",
    "        DeadTraces()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Assurez-vous que l'initialisation et l'utilisation de votre Dataset et DataLoader soient correctes :\n",
    "train_dataset, validate_dataset, test_dataset = create_datasets(data_path, dataset_name)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=None)\n",
    "\n",
    "plot_a_sample(train_dataloader, i=0)\n"
   ],
   "id": "b2e4fe890b7d6e2e",
   "execution_count": 52,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8c3b099d3e82d252",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
