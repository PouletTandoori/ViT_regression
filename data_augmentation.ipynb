{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# I- Begin like ViT_TransferLearning.py",
   "id": "b9e76c46a8afe45f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:34:25.408738Z",
     "start_time": "2024-10-02T17:34:17.798294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from random import random\n",
    "from Utilities import *\n",
    "from data_augmentation import *\n",
    "\n",
    "# Paths to search for data\n",
    "data_path = '/home/rbertille/data/pycharm/ViT_project/pycharm_Geoflow/GeoFlow/Tutorial/Datasets/'\n",
    "dataset_name = 'TutorialDataset'\n",
    "files_path = os.path.join(data_path, dataset_name)\n",
    "\n",
    "train_folder = glob.glob(f'{files_path}/train/*')\n",
    "validate_folder = glob.glob(f'{files_path}/validate/*')\n",
    "test_folder = glob.glob(f'{files_path}/test/*')\n",
    "\n",
    "#def data augmentation, without any augmentation for the moment\n",
    "data_aug = transforms.Compose(\n",
    "    [\n",
    "\n",
    "    ]\n",
    ")\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.data, self.labels = self.load_data_from_folder(folder)\n",
    "        self.transform = transform #ici\n",
    "\n",
    "    def load_data_from_folder(self, folder):\n",
    "        data = []\n",
    "        labels = []\n",
    "\n",
    "        for file_path in folder:\n",
    "            with h5.File(file_path, 'r') as h5file:\n",
    "                inputs = h5file['shotgather'][:]\n",
    "                #take second half only= Z component\n",
    "                inputs = inputs[:,int(inputs.shape[1]/2):]\n",
    "                labels_data = h5file['vsdepth'][:]\n",
    "\n",
    "                # print('data shape:',inputs.shape)\n",
    "                # print('min data=',np.min(inputs))\n",
    "                inputs = (inputs - np.min(inputs)) / (np.max(inputs) - np.min(inputs))\n",
    "\n",
    "                # reshape data\n",
    "                inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "                transform_resize = transforms.Compose([\n",
    "                    transforms.ToPILImage(),\n",
    "                    #transforms.Resize((224, 224)),\n",
    "                    transforms.ToTensor()\n",
    "                ])\n",
    "                inputs = transform_resize(inputs)\n",
    "\n",
    "                if inputs.shape[0] == 1:  # Si l'image est en grayscale\n",
    "                    inputs = inputs.repeat(3, 1, 1)  # Convertir en RGB\n",
    "                inputs = inputs.numpy()\n",
    "\n",
    "                data.append(inputs)\n",
    "                labels.append(labels_data)\n",
    "\n",
    "        data = np.array(data)\n",
    "\n",
    "        labels = np.array(labels)\n",
    "        return data, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.data[idx]\n",
    "        labels = self.labels[idx]\n",
    "\n",
    "        # Convert inputs and labels to Tensors\n",
    "        inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        sample = {'data': inputs, 'label': labels}\n",
    "\n",
    "        if self.transform:\n",
    "            sample['data'] = self.transform(sample['data']) #ici\n",
    "\n",
    "        return sample\n",
    "\n",
    "def create_datasets(data_path, dataset_name):\n",
    "    train_folder = glob.glob(os.path.join(data_path, dataset_name, 'train', '*'))\n",
    "    validate_folder = glob.glob(os.path.join(data_path, dataset_name, 'validate', '*'))\n",
    "    test_folder = glob.glob(os.path.join(data_path, dataset_name, 'test', '*'))\n",
    "\n",
    "    train_dataset = CustomDataset(train_folder,transform=data_aug)\n",
    "    validate_dataset = CustomDataset(validate_folder)\n",
    "    test_dataset = CustomDataset(test_folder)\n",
    "\n",
    "    return train_dataset, validate_dataset, test_dataset\n",
    "\n",
    "\n",
    "train_dataset, _, _ = create_datasets(data_path, dataset_name)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=None)"
   ],
   "id": "d2ad31bd93d83c71",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# I- Example without any augmentation",
   "id": "afd4ca3c101460d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:34:25.669060Z",
     "start_time": "2024-10-02T17:34:25.411166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#display the first example\n",
    "#apply on our example:\n",
    "image=train_dataloader.dataset.data[0];nb_traces=image.shape[2]\n",
    "modified_image = data_aug(image)\n",
    "#plot the modified example\n",
    "time_vector = np.linspace(0,1.5,modified_image.shape[0])\n",
    "plt.imshow(modified_image[0], aspect='auto', cmap='gray',extent=[0,nb_traces,time_vector[-1],time_vector[0]])\n",
    "plt.xlabel('Traces')\n",
    "plt.ylabel('Time (s)')\n",
    "plt.show()\n"
   ],
   "id": "c6bfbaf91eaf4149",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# II - Plot a sample with a trace shift\n",
    "\n",
    "Purpose is to augment the data by shifting the traces by a random number of grid points. The number of grid points to shift is a random number between 0 and a given ratio of the number of grid points in the data. The traces are shifted to the top/bottom, and the values of the new grid points are set to 0."
   ],
   "id": "89c9daeb30ba6005"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:34:25.933349Z",
     "start_time": "2024-10-02T17:34:25.670857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#create transform\n",
    "# Compose the custom augmentations with available augmentations.\n",
    "data_aug = transforms.Compose(\n",
    "    [\n",
    "        TraceShift(shift_ratio=0.02)\n",
    "    ]\n",
    ")\n",
    "#transform image into torch tensor\n",
    "torch_image = torch.tensor(image, dtype=torch.float32)\n",
    "modified_image = data_aug(torch_image)\n",
    "#plot the modified example\n",
    "plt.imshow(modified_image[0], aspect='auto', cmap='gray',extent=[0,nb_traces,time_vector[-1],time_vector[0]])\n",
    "plt.xlabel('Traces')\n",
    "plt.ylabel('Time (s)')\n",
    "plt.show()"
   ],
   "id": "27af02118b7d882f",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# III - Plot a sample with missing traces\n",
    "\n",
    "Purpose is to augment the data by randomly removing a given ratio of traces from the data. The number of traces to remove is a random number between 0 and a given ratio of the number of traces in the data. The removed traces are replaced by average values of the trace."
   ],
   "id": "7980b66fbb921726"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:34:26.168369Z",
     "start_time": "2024-10-02T17:34:25.935220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#create transform\n",
    "# Compose the custom augmentations with available augmentations.\n",
    "data_aug = transforms.Compose(\n",
    "    [\n",
    "        MissingTraces(missing_trace_ratio=0.04)\n",
    "    ]\n",
    ")\n",
    "#transform image into torch tensor\n",
    "torch_image = torch.tensor(image, dtype=torch.float32)\n",
    "modified_image = data_aug(torch_image)\n",
    "#plot the modified example\n",
    "plt.imshow(modified_image[0], aspect='auto', cmap='gray',extent=[0,nb_traces,time_vector[-1],time_vector[0]])\n",
    "plt.xlabel('Traces')\n",
    "plt.ylabel('Time (s)')\n",
    "plt.show()"
   ],
   "id": "ba4c302bca6261d8",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# IV - Plot a sample with random dead traces\n",
    "\n",
    "Purpose is to augment the data by randomly setting a given ratio of traces to 0. The number of traces to set to 0 is a random number between 0 and a given ratio of the number of traces in the data.\n"
   ],
   "id": "a25eb9a8906fdce3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:34:26.405635Z",
     "start_time": "2024-10-02T17:34:26.170831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#create transform\n",
    "# Compose the custom augmentations with available augmentations.\n",
    "data_aug = transforms.Compose(\n",
    "    [\n",
    "        DeadTraces(dead_trace_ratio=0.04)\n",
    "    ]\n",
    ")\n",
    "#transform image into torch tensor\n",
    "torch_image = torch.tensor(image, dtype=torch.float32)\n",
    "modified_image = data_aug(torch_image)\n",
    "#plot the modified example\n",
    "plt.imshow(modified_image[0], aspect='auto', cmap='gray',extent=[0,nb_traces,time_vector[-1],time_vector[0]])\n",
    "plt.xlabel('Traces')\n",
    "plt.ylabel('Time (s)')\n",
    "plt.show()"
   ],
   "id": "d495242269f31d33",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# V - Plot a sample with random noise\n",
    "\n",
    "Purpose is to augment the data by adding random noise to the data. The noise is a value around the mean, its strength is controlled by the standard deviation."
   ],
   "id": "1b8031c66fe2b25a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:34:26.677963Z",
     "start_time": "2024-10-02T17:34:26.407125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#create transform\n",
    "# Compose the custom augmentations with available augmentations.\n",
    "data_aug = transforms.Compose(\n",
    "    [\n",
    "        GaussianNoise(mean=0., std=0.05)\n",
    "    ]\n",
    ")\n",
    "#transform image into torch tensor\n",
    "torch_image = torch.tensor(image, dtype=torch.float32)\n",
    "modified_image = data_aug(torch_image)\n",
    "#plot the modified example\n",
    "plt.imshow(modified_image[0], aspect='auto', cmap='gray',extent=[0,nb_traces,time_vector[-1],time_vector[0]])\n",
    "plt.xlabel('Traces')\n",
    "plt.ylabel('Time (s)')\n",
    "plt.show()"
   ],
   "id": "e195470aee456d29",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# VI - Put everything together\n",
    "\n",
    "Show an example of what happen if we applay all the augmentations on our example."
   ],
   "id": "114780bfcfa2e556"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:34:26.960809Z",
     "start_time": "2024-10-02T17:34:26.679475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#create transform\n",
    "# Compose the custom augmentations with available augmentations.\n",
    "data_aug = transforms.Compose(\n",
    "    [\n",
    "        TraceShift2(shift_ratio=0.01,contiguous_ratio=0.2),\n",
    "        GaussianNoise(mean=0., std=0.05),\n",
    "        MissingTraces(missing_trace_ratio=0.05),\n",
    "        DeadTraces(dead_trace_ratio=0.04)\n",
    "    ]\n",
    ")\n",
    "#transform image into torch tensor\n",
    "torch_image = torch.tensor(image, dtype=torch.float32)\n",
    "modified_image = data_aug(torch_image)\n",
    "#plot the modified example\n",
    "plt.imshow(modified_image[0], aspect='auto', cmap='gray',extent=[0,nb_traces,time_vector[-1],time_vector[0]])\n",
    "plt.xlabel('Traces')\n",
    "plt.ylabel('Time (s)')\n",
    "plt.show()"
   ],
   "id": "d61a3c51657bd93b",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# VII - Test a better way to shift the traces\n",
    "\n",
    "The idea here is to shift only a small amount of traces, moreover we want to shift traces close one to each other."
   ],
   "id": "cec714c789900eb1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:34:26.964873Z",
     "start_time": "2024-10-02T17:34:26.962301Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ca95d2c3eff39b82",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:34:27.206371Z",
     "start_time": "2024-10-02T17:34:26.966272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#create transform\n",
    "# Compose the custom augmentations with available augmentations.\n",
    "data_aug = transforms.Compose(\n",
    "    [\n",
    "        TraceShift2(shift_ratio=0.01,contiguous_ratio=0.2)\n",
    "    ]\n",
    ")\n",
    "#transform image into torch tensor\n",
    "torch_image = torch.tensor(image, dtype=torch.float32)\n",
    "modified_image = data_aug(torch_image)\n",
    "#plot the modified example\n",
    "plt.imshow(modified_image[0], aspect='auto', cmap='gray',extent=[0,nb_traces,time_vector[-1],time_vector[0]])\n",
    "plt.xlabel('Traces')\n",
    "plt.ylabel('Time (s)')\n",
    "plt.show()"
   ],
   "id": "586e513b3951482a",
   "execution_count": 8,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
